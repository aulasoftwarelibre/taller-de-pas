{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Inicio \u00b6 Este taller forma parte de las actividades del Aula de Software Libre de la Universidad de C\u00f3rdoba . El contenido del mismo es en parte de producci\u00f3n propia, en parte de otros manuales libres que pueden encontrarse en la secci\u00f3n de Referencias . Contenido \u00b6 Inicio Sesi\u00f3n 1 Sesi\u00f3n 2 Referencias Agradecimientos \u00b6 Este curso ha sido impartido por las siguientes personas: Alberto Cano Antonio Moruno David P\u00e9rez David Salcedo Javier de Santiago Moises Moyano Marcos Rivera Marcos Rodr\u00edguez Licencia \u00b6 El material est\u00e1 publicado con licencia Atribuci\u00f3n-NoComercial 4.0 Internacional (CC BY-NC 4.0)","title":"Inicio"},{"location":"#inicio","text":"Este taller forma parte de las actividades del Aula de Software Libre de la Universidad de C\u00f3rdoba . El contenido del mismo es en parte de producci\u00f3n propia, en parte de otros manuales libres que pueden encontrarse en la secci\u00f3n de Referencias .","title":"Inicio"},{"location":"#contenido","text":"Inicio Sesi\u00f3n 1 Sesi\u00f3n 2 Referencias","title":"Contenido"},{"location":"#agradecimientos","text":"Este curso ha sido impartido por las siguientes personas: Alberto Cano Antonio Moruno David P\u00e9rez David Salcedo Javier de Santiago Moises Moyano Marcos Rivera Marcos Rodr\u00edguez","title":"Agradecimientos"},{"location":"#licencia","text":"El material est\u00e1 publicado con licencia Atribuci\u00f3n-NoComercial 4.0 Internacional (CC BY-NC 4.0)","title":"Licencia"},{"location":"referencias/","text":"Referencias \u00b6 Documentaci\u00f3n oficial en ingl\u00e9s . https://medium.com/google-cloud/kubernetes-nodeport-vs-loadbalancer-vs-ingress-when-should-i-use-what-922f010849e0 https://ualmtorres.github.io/SeminarioKubernetes/#trueservicios","title":"Referencias"},{"location":"referencias/#referencias","text":"Documentaci\u00f3n oficial en ingl\u00e9s . https://medium.com/google-cloud/kubernetes-nodeport-vs-loadbalancer-vs-ingress-when-should-i-use-what-922f010849e0 https://ualmtorres.github.io/SeminarioKubernetes/#trueservicios","title":"Referencias"},{"location":"Sesion-1/Apache/","text":"Creaci\u00f3n de una aplicacion React \u00b6 Creaci\u00f3n de una imagen Apache \u00b6 Para la creaci\u00f3n de este servidor utilizaremos la imagen httpd , en la que haremos deploy de un servidor Apache, para m\u00e1s adelante en el workshop, hagamos deployment de un frontend en React a trav\u00e9s de esta imagen. [ ! ] El repositorio desde el que empezamos es: https://github.com/mark-doblefilo/pas-workshop o tambi\u00e9n podemos utilizar: npx create-react-app pas-workshop Creando nuestra imagen con Dockerfile \u00b6 Primero de todo, para generar una imagen a partir de la imagen base httpd, necesitaremos crear nuestra propia imagen. Para ello creamos el archivo Dockerfile: FROM httpd EXPOSE 80 CMD [ \"httpd-foreground\" ] Tras esto, ejecutariamos el siguiente comando en terminal: docker build -t apache-image . Con el siguiente resultado: Sending build context to Docker daemon 191.1MB Step 1/3 : FROM httpd ---> 0b932df43057 Step 2/3 : EXPOSE 80 ---> Using cache ---> 024fc3423791 Step 3/3 : CMD [\"httpd-foreground\"] ---> Using cache ---> dc01a168338b Successfully built dc01a168338b Successfully tagged apache-image:latest Creando nuestro contenedor a partir de la imagen Apache \u00b6 Ya tenemos creada nuestra imagen con nombre apache-image . Lo siguiente ser\u00eda generar el contenedor para iniciar y probar nuestra imagen: docker run -d --name apache-container -p 8080:80 apache-image Comando Podr\u00edamos ver el estado del contenedor ejecutando: docker ps Ahora podemos entrar en la p\u00e1gina web, recordemos que con la flag p hemos asignado el puerto 80 de nuestro apache (puerto por defecto) al puerto 8080 de nuestro localhost. Para probar nuestro contenedor abriremos un navegador e iremos a localhost:8080 Creando nuestro entorno de desarrollo en React \u00b6 Para crear nuestro entorno de desarrollo utilizaremos otra imagen, en este caso utilizaremos node . Node.js es una plataforma basada en Javascript para server-side y networking applications. Adem\u00e1s esta imagen base nos permite algo denominado hot reload tal que cuando modifiquemos alguna cosa en nuestro c\u00f3digo se actualice en nuestro contenedor y podamos verlo al instante. Adem\u00e1s utilizaremos docker-compose que nos permitir\u00e1 facilitarnos la construcci\u00f3n de la imagen y el contenedor. Creando nuestro Dockerfile y docker-compose \u00b6 Como en la anterior caso, empezaremos con la creaci\u00f3n de un Dockerfile, en este caso partiremos de una imagen base diferente pero que nos ayudar\u00e1 en nuestra etapa de desarrollo. FROM node:13.12.0-alpine WORKDIR /app # /app/node_modules/.bin to $PATH ENV PATH /app/node_modules/.bin: $PATH COPY package.json ./ COPY package-lock.json ./ RUN npm install --silent RUN npm install react-scripts@3.4.1 -g --silent COPY . ./ CMD [ \"npm\" , \"start\" ] Crearemos un .dockerignore para hacer que la creaci\u00f3n de nuestra imagen sea mucho m\u00e1s r\u00e1pida: node_modules build .dockerignore Dockerfile Dockerfile.prod Y por \u00faltimo crearemos el docker-compose.yml: version : '3.7' services : react-service : container_name : react-container build : context : . dockerfile : Dockerfile volumes : - '.:/app' - '/app/node_modules' ports : - 8080:3000 environment : - CHOKIDAR_USEPOLLING=true Creando nuestro entorno de producci\u00f3n \u00b6 Seguiremos con los mismos pasos (Dockerfile y docker-compose): Dockerfile.prod # STAGE 1 FROM node:13.12.0-alpine as build WORKDIR /app # /app/node_modules/.bin to $PATH ENV PATH /app/node_modules/.bin: $PATH COPY package.json ./ COPY package-lock.json ./ RUN npm ci --silent RUN npm install react-scripts@3.4.1 -g --silent COPY . ./ RUN npm run build # STAGE 2 FROM httpd COPY --from = build /app/build /usr/local/apache2/htdocs EXPOSE 80 CMD [ \"httpd-foreground\" ] docker-compose.prod.yml version : '3.7' services : react-prod : container_name : react-prod build : context : . dockerfile : Dockerfile.prod ports : - '80:80' Para ejecutar nuestros servicios de producci\u00f3n utilizaremos: docker-compose -f \"docker-compose.prod.yml\" up -d --build Importante El comando docker-compose ps nos mostrar\u00e1 los servicios de un fichero (por defecto: docker-compose.yml). Si nuestro fichero tiene un nombre diferente, entonces lo tendremos que indicar con la flag -f \"example.yml\". Y ya tendremos nuestro React dockerizado y en producci\u00f3n, el puerto indicado es 80 (conexiones http), entonces al abrir un navegador y poner en la URL: localhost:80","title":"Creaci\u00f3n de una aplicacion React"},{"location":"Sesion-1/Apache/#creacion-de-una-aplicacion-react","text":"","title":"Creaci\u00f3n de una aplicacion React"},{"location":"Sesion-1/Apache/#creacion-de-una-imagen-apache","text":"Para la creaci\u00f3n de este servidor utilizaremos la imagen httpd , en la que haremos deploy de un servidor Apache, para m\u00e1s adelante en el workshop, hagamos deployment de un frontend en React a trav\u00e9s de esta imagen. [ ! ] El repositorio desde el que empezamos es: https://github.com/mark-doblefilo/pas-workshop o tambi\u00e9n podemos utilizar: npx create-react-app pas-workshop","title":"Creaci\u00f3n de una imagen Apache"},{"location":"Sesion-1/Apache/#creando-nuestra-imagen-con-dockerfile","text":"Primero de todo, para generar una imagen a partir de la imagen base httpd, necesitaremos crear nuestra propia imagen. Para ello creamos el archivo Dockerfile: FROM httpd EXPOSE 80 CMD [ \"httpd-foreground\" ] Tras esto, ejecutariamos el siguiente comando en terminal: docker build -t apache-image . Con el siguiente resultado: Sending build context to Docker daemon 191.1MB Step 1/3 : FROM httpd ---> 0b932df43057 Step 2/3 : EXPOSE 80 ---> Using cache ---> 024fc3423791 Step 3/3 : CMD [\"httpd-foreground\"] ---> Using cache ---> dc01a168338b Successfully built dc01a168338b Successfully tagged apache-image:latest","title":"Creando nuestra imagen con Dockerfile"},{"location":"Sesion-1/Apache/#creando-nuestro-contenedor-a-partir-de-la-imagen-apache","text":"Ya tenemos creada nuestra imagen con nombre apache-image . Lo siguiente ser\u00eda generar el contenedor para iniciar y probar nuestra imagen: docker run -d --name apache-container -p 8080:80 apache-image Comando Podr\u00edamos ver el estado del contenedor ejecutando: docker ps Ahora podemos entrar en la p\u00e1gina web, recordemos que con la flag p hemos asignado el puerto 80 de nuestro apache (puerto por defecto) al puerto 8080 de nuestro localhost. Para probar nuestro contenedor abriremos un navegador e iremos a localhost:8080","title":"Creando nuestro contenedor a partir de la imagen Apache"},{"location":"Sesion-1/Apache/#creando-nuestro-entorno-de-desarrollo-en-react","text":"Para crear nuestro entorno de desarrollo utilizaremos otra imagen, en este caso utilizaremos node . Node.js es una plataforma basada en Javascript para server-side y networking applications. Adem\u00e1s esta imagen base nos permite algo denominado hot reload tal que cuando modifiquemos alguna cosa en nuestro c\u00f3digo se actualice en nuestro contenedor y podamos verlo al instante. Adem\u00e1s utilizaremos docker-compose que nos permitir\u00e1 facilitarnos la construcci\u00f3n de la imagen y el contenedor.","title":"Creando nuestro entorno de desarrollo en React"},{"location":"Sesion-1/Apache/#creando-nuestro-dockerfile-y-docker-compose","text":"Como en la anterior caso, empezaremos con la creaci\u00f3n de un Dockerfile, en este caso partiremos de una imagen base diferente pero que nos ayudar\u00e1 en nuestra etapa de desarrollo. FROM node:13.12.0-alpine WORKDIR /app # /app/node_modules/.bin to $PATH ENV PATH /app/node_modules/.bin: $PATH COPY package.json ./ COPY package-lock.json ./ RUN npm install --silent RUN npm install react-scripts@3.4.1 -g --silent COPY . ./ CMD [ \"npm\" , \"start\" ] Crearemos un .dockerignore para hacer que la creaci\u00f3n de nuestra imagen sea mucho m\u00e1s r\u00e1pida: node_modules build .dockerignore Dockerfile Dockerfile.prod Y por \u00faltimo crearemos el docker-compose.yml: version : '3.7' services : react-service : container_name : react-container build : context : . dockerfile : Dockerfile volumes : - '.:/app' - '/app/node_modules' ports : - 8080:3000 environment : - CHOKIDAR_USEPOLLING=true","title":"Creando nuestro Dockerfile y docker-compose"},{"location":"Sesion-1/Apache/#creando-nuestro-entorno-de-produccion","text":"Seguiremos con los mismos pasos (Dockerfile y docker-compose): Dockerfile.prod # STAGE 1 FROM node:13.12.0-alpine as build WORKDIR /app # /app/node_modules/.bin to $PATH ENV PATH /app/node_modules/.bin: $PATH COPY package.json ./ COPY package-lock.json ./ RUN npm ci --silent RUN npm install react-scripts@3.4.1 -g --silent COPY . ./ RUN npm run build # STAGE 2 FROM httpd COPY --from = build /app/build /usr/local/apache2/htdocs EXPOSE 80 CMD [ \"httpd-foreground\" ] docker-compose.prod.yml version : '3.7' services : react-prod : container_name : react-prod build : context : . dockerfile : Dockerfile.prod ports : - '80:80' Para ejecutar nuestros servicios de producci\u00f3n utilizaremos: docker-compose -f \"docker-compose.prod.yml\" up -d --build Importante El comando docker-compose ps nos mostrar\u00e1 los servicios de un fichero (por defecto: docker-compose.yml). Si nuestro fichero tiene un nombre diferente, entonces lo tendremos que indicar con la flag -f \"example.yml\". Y ya tendremos nuestro React dockerizado y en producci\u00f3n, el puerto indicado es 80 (conexiones http), entonces al abrir un navegador y poner en la URL: localhost:80","title":"Creando nuestro entorno de producci\u00f3n"},{"location":"Sesion-1/Contenedores/","text":"Contenedores \u00b6 Los contenedores son instancias de las im\u00e1genes que hemos creado o hemos descargado y que se ejecutan de forma aislada. Listado \u00b6 Para ver el listado de contenedores, usaremos: - docker container ls o - docker ps (versi\u00f3n abreviada) Si lo ejecutamos, nos dar\u00e1 un listado vac\u00edo porque no hay ning\u00fan contenedor activo. para ver el listado de contenedores parados, usaremos: - docker container ls -a o - docker ps -a (versi\u00f3n abreviada) Ejecutar comandos dentro de una contenedor \u00b6 Ya hemos usado el comando docker run para crear e iniciar nuestro contenedro, pero tambi\u00e9n podemos usar este comando para ejecutar programas que est\u00e9n dentro del contenedor: docker run --name ubuntu_bash --rm -i -t ubuntu bash Pero esra forma de ejecutar las cosas, crea un nuevo contenedor. Si queremos ejecutar un comando en un contenedor que ya est\u00e9 iniciado, usaremos: docker container exec Sin cerrar este terminal, ejecutamos en otra terminal: docker exec -w /tmp ubuntu_bash touch my_file.sh Donde: -w -> indica el directorio de trabajo ubuntu_bash -> indicamos el contenedor donde queremos ejecutar el comando touch my_file.sh -> el comando a ejecutar Para cerrar y borrar el contenedor, usamos: Control+c Iniciar un contenedor \u00b6 Para inciar un contenedor parado, usaremos: docker container start Detener un contenedor \u00b6 Para detener un contenedor iniciado, usaremos: docker container stop (id / nombre) Indicando su id o su nombre Borrar un contenedor \u00b6 Un contenedor parada ocupa espacio. Si hemos dejado de necesitar uin contenedor, podemos usar el siguiente comando para borrarlo: docker container rm (id / nombre) Indicando al igual que con la opci\u00f3n de detener, su id o nombre.","title":"Contenedores"},{"location":"Sesion-1/Contenedores/#contenedores","text":"Los contenedores son instancias de las im\u00e1genes que hemos creado o hemos descargado y que se ejecutan de forma aislada.","title":"Contenedores"},{"location":"Sesion-1/Contenedores/#listado","text":"Para ver el listado de contenedores, usaremos: - docker container ls o - docker ps (versi\u00f3n abreviada) Si lo ejecutamos, nos dar\u00e1 un listado vac\u00edo porque no hay ning\u00fan contenedor activo. para ver el listado de contenedores parados, usaremos: - docker container ls -a o - docker ps -a (versi\u00f3n abreviada)","title":"Listado"},{"location":"Sesion-1/Contenedores/#ejecutar-comandos-dentro-de-una-contenedor","text":"Ya hemos usado el comando docker run para crear e iniciar nuestro contenedro, pero tambi\u00e9n podemos usar este comando para ejecutar programas que est\u00e9n dentro del contenedor: docker run --name ubuntu_bash --rm -i -t ubuntu bash Pero esra forma de ejecutar las cosas, crea un nuevo contenedor. Si queremos ejecutar un comando en un contenedor que ya est\u00e9 iniciado, usaremos: docker container exec Sin cerrar este terminal, ejecutamos en otra terminal: docker exec -w /tmp ubuntu_bash touch my_file.sh Donde: -w -> indica el directorio de trabajo ubuntu_bash -> indicamos el contenedor donde queremos ejecutar el comando touch my_file.sh -> el comando a ejecutar Para cerrar y borrar el contenedor, usamos: Control+c","title":"Ejecutar comandos dentro de una contenedor"},{"location":"Sesion-1/Contenedores/#iniciar-un-contenedor","text":"Para inciar un contenedor parado, usaremos: docker container start","title":"Iniciar un contenedor"},{"location":"Sesion-1/Contenedores/#detener-un-contenedor","text":"Para detener un contenedor iniciado, usaremos: docker container stop (id / nombre) Indicando su id o su nombre","title":"Detener un contenedor"},{"location":"Sesion-1/Contenedores/#borrar-un-contenedor","text":"Un contenedor parada ocupa espacio. Si hemos dejado de necesitar uin contenedor, podemos usar el siguiente comando para borrarlo: docker container rm (id / nombre) Indicando al igual que con la opci\u00f3n de detener, su id o nombre.","title":"Borrar un contenedor"},{"location":"Sesion-1/Im%C3%A1genes/","text":"Im\u00e1genes \u00b6 Son la bade de Docker ya que nuestros contenedores se iniciar\u00e1n a partir de ellas. Como ya se indic\u00f3 en la introducci\u00f3n, es una plantilla de solo lectura, que se crea incorporando los requisitos necesarios para cumplir el objetivo para el cual fue creada. Buscar im\u00e1genes \u00b6 Crear una imagen desde cero supone un esfuerzo grand\u00edsimo, as\u00ed que lo normal es partir o usar una ya creada. Para ello buscaremos en los registros que son el lugar donde se almacenan. Hay un registro oficial https://hub.docker.com , pero nada impide a otras organizaciones, o incluso a nosotros mismo, tener un registro propio. Estos pueden ser tanto p\u00fablicos como privados. Vamos a imaginarnos que queremos crear una web con Wordpress . Si buscamos en el registro, encontraremos una imagen llamada wordpress , con la etiqueta oficial. La recomendaci\u00f3n es que siempre busquemos im\u00e1genes oficiales, ya que est\u00e1n mantenidas y bien documentadas. Gesti\u00f3n de im\u00e1genes \u00b6 Descarga \u00b6 Las imagenes que nos descargamos, se identifican tanto por nombre como por versi\u00f3n. De esa manera, podemos tener distintas versiones de una misma imagen. En la p\u00e1gina del registro veremos una pesta\u00f1a con el nombre Tags , con las versiones disponibles. Para usar una en concreto, se usa dos puntos seguido del nombre de la versi\u00f3n. SI no se indica nada, como hasta ahora, por defecto se descarga la etiquetata como latest Para descargar im\u00e1genes, usaremos: docker pull Listado \u00b6 Para ver el listado de imagenes disponibles, usaremos: docker images Borrado \u00b6 Si queremos dejar de usar alguna imagen, usaremos: docker rmi","title":"Im\u00e1genes"},{"location":"Sesion-1/Im%C3%A1genes/#imagenes","text":"Son la bade de Docker ya que nuestros contenedores se iniciar\u00e1n a partir de ellas. Como ya se indic\u00f3 en la introducci\u00f3n, es una plantilla de solo lectura, que se crea incorporando los requisitos necesarios para cumplir el objetivo para el cual fue creada.","title":"Im\u00e1genes"},{"location":"Sesion-1/Im%C3%A1genes/#buscar-imagenes","text":"Crear una imagen desde cero supone un esfuerzo grand\u00edsimo, as\u00ed que lo normal es partir o usar una ya creada. Para ello buscaremos en los registros que son el lugar donde se almacenan. Hay un registro oficial https://hub.docker.com , pero nada impide a otras organizaciones, o incluso a nosotros mismo, tener un registro propio. Estos pueden ser tanto p\u00fablicos como privados. Vamos a imaginarnos que queremos crear una web con Wordpress . Si buscamos en el registro, encontraremos una imagen llamada wordpress , con la etiqueta oficial. La recomendaci\u00f3n es que siempre busquemos im\u00e1genes oficiales, ya que est\u00e1n mantenidas y bien documentadas.","title":"Buscar im\u00e1genes"},{"location":"Sesion-1/Im%C3%A1genes/#gestion-de-imagenes","text":"","title":"Gesti\u00f3n de im\u00e1genes"},{"location":"Sesion-1/Im%C3%A1genes/#descarga","text":"Las imagenes que nos descargamos, se identifican tanto por nombre como por versi\u00f3n. De esa manera, podemos tener distintas versiones de una misma imagen. En la p\u00e1gina del registro veremos una pesta\u00f1a con el nombre Tags , con las versiones disponibles. Para usar una en concreto, se usa dos puntos seguido del nombre de la versi\u00f3n. SI no se indica nada, como hasta ahora, por defecto se descarga la etiquetata como latest Para descargar im\u00e1genes, usaremos: docker pull","title":"Descarga"},{"location":"Sesion-1/Im%C3%A1genes/#listado","text":"Para ver el listado de imagenes disponibles, usaremos: docker images","title":"Listado"},{"location":"Sesion-1/Im%C3%A1genes/#borrado","text":"Si queremos dejar de usar alguna imagen, usaremos: docker rmi","title":"Borrado"},{"location":"Sesion-1/Instalaci%C3%B3n/","text":"Instalaci\u00f3n \u00b6 Existen dos versiones de Dcoker, una libre y otra que no lo es. Nos ouparemos exclusivamente de la primera: Docker CE (Community Edition) Disponibilidad \u00b6 Docker CE est\u00e1 disponible para los siguientes sistemas GNU/Linux: CentOS, Debian, Fedora , Raspbian y Ubuntu. Y esta soportado por aruitecturas como x86_64 / amd64 , ARM y ARM64 / AARCH64. Instalaci\u00f3n \u00b6 Debido a que, dependiendo de la distribuci\u00f3n, la forma de instalarlo difiere, es mejor consultar la documentaci\u00f3n oficial para saber como instalar Docker en tu m\u00e1quina. Ubuntu: https://docs.docker.com/engine/install/ubuntu/ Debian: https://docs.docker.com/engine/install/debian/ CentOS: https://docs.docker.com/engine/install/centos/ Fedora: https://docs.docker.com/engine/install/fedora/ Para saber si tienes Docker bien instalado, los tutoriales oficiales siempre te indican que inicies un contenedor de ejemplo. Esto es lo que sucede: $ sudo docker run hello-world Unable to find image 'hello-world:latest' locally latest: Pulling from library/hello-world d1725b59e92d: Pull complete Digest: sha256:0add3ace90ecb4adbf7777e9aacf18357296e799f81cabc9fde470971e499788 Status: Downloaded newer image for hello-world:latest Hello from Docker! This message shows that your installation appears to be working correctly. To generate this message, Docker took the following steps: 1. The Docker client contacted the Docker daemon. 2. The Docker daemon pulled the \"hello-world\" image from the Docker Hub. (amd64) 3. The Docker daemon created a new container from that image which runs the executable that produces the output you are currently reading. 4. The Docker daemon streamed that output to the Docker client, which sent it to your terminal. To try something more ambitious, you can run an Ubuntu container with: $ docker run -it ubuntu bash Share images, automate workflows, and more with a free Docker ID: https://hub.docker.com/ For more examples and ideas, visit: https://docs.docker.com/get-started/ ``` En la l\u00ednea 1 estamos ejecutando el cliente de Docker, y estamos indicando que queremos ejecutar un contenedor a partir de la imagen hello-world del registro p\u00fablico de Docker. Si es la primera vez que hemos ejecutado esa imagen, nos aparecer\u00e1 la l\u00ednea 2, que indica que la imagen no puede ser encontrada y va a proceder a buscarla, por defecto, en el registro p\u00fablico. Si tenemos conexi\u00f3n a Internet se descargar\u00e1 la imagen (l\u00ednea 6) y autom\u00e1ticamente crear\u00e1 un contenedor. Tanto si se ha descargado la imagen o ya estaba descargada, el contenedor se ejecutar\u00e1, obteniendo el texto de bienvenida que se ve en el cuadro anterior. Configuraci\u00f3n del usuario \u00b6 Si estamos usando Docker en nuestro ordenador, podemos configurar nuestro usuario para usar el cliente sin tener que poner sudo delante. Para ello, debemos de ejecutar el siguiente comando: sudo usermod -aG docker $USER Para que surjan efecto los cambios, debemos de cerrar y volver a abrir la sesi\u00f3n. Herramientas \u00b6 Tambi\u00e9n es necesario tener una herramienta llamada Docker Compose. Puedes instalarla siguiendo las instrucciones que se encuentra en la p\u00e1gina de Instalaci\u00f3n de Docker Compose . Sin embargo, si usas Ubuntu o Debian, podemos instalarlo con el siguiente comando: sudo apt install docker-compose","title":"Instalaci\u00f3n"},{"location":"Sesion-1/Instalaci%C3%B3n/#instalacion","text":"Existen dos versiones de Dcoker, una libre y otra que no lo es. Nos ouparemos exclusivamente de la primera: Docker CE (Community Edition)","title":"Instalaci\u00f3n"},{"location":"Sesion-1/Instalaci%C3%B3n/#disponibilidad","text":"Docker CE est\u00e1 disponible para los siguientes sistemas GNU/Linux: CentOS, Debian, Fedora , Raspbian y Ubuntu. Y esta soportado por aruitecturas como x86_64 / amd64 , ARM y ARM64 / AARCH64.","title":"Disponibilidad"},{"location":"Sesion-1/Instalaci%C3%B3n/#instalacion_1","text":"Debido a que, dependiendo de la distribuci\u00f3n, la forma de instalarlo difiere, es mejor consultar la documentaci\u00f3n oficial para saber como instalar Docker en tu m\u00e1quina. Ubuntu: https://docs.docker.com/engine/install/ubuntu/ Debian: https://docs.docker.com/engine/install/debian/ CentOS: https://docs.docker.com/engine/install/centos/ Fedora: https://docs.docker.com/engine/install/fedora/ Para saber si tienes Docker bien instalado, los tutoriales oficiales siempre te indican que inicies un contenedor de ejemplo. Esto es lo que sucede: $ sudo docker run hello-world Unable to find image 'hello-world:latest' locally latest: Pulling from library/hello-world d1725b59e92d: Pull complete Digest: sha256:0add3ace90ecb4adbf7777e9aacf18357296e799f81cabc9fde470971e499788 Status: Downloaded newer image for hello-world:latest Hello from Docker! This message shows that your installation appears to be working correctly. To generate this message, Docker took the following steps: 1. The Docker client contacted the Docker daemon. 2. The Docker daemon pulled the \"hello-world\" image from the Docker Hub. (amd64) 3. The Docker daemon created a new container from that image which runs the executable that produces the output you are currently reading. 4. The Docker daemon streamed that output to the Docker client, which sent it to your terminal. To try something more ambitious, you can run an Ubuntu container with: $ docker run -it ubuntu bash Share images, automate workflows, and more with a free Docker ID: https://hub.docker.com/ For more examples and ideas, visit: https://docs.docker.com/get-started/ ``` En la l\u00ednea 1 estamos ejecutando el cliente de Docker, y estamos indicando que queremos ejecutar un contenedor a partir de la imagen hello-world del registro p\u00fablico de Docker. Si es la primera vez que hemos ejecutado esa imagen, nos aparecer\u00e1 la l\u00ednea 2, que indica que la imagen no puede ser encontrada y va a proceder a buscarla, por defecto, en el registro p\u00fablico. Si tenemos conexi\u00f3n a Internet se descargar\u00e1 la imagen (l\u00ednea 6) y autom\u00e1ticamente crear\u00e1 un contenedor. Tanto si se ha descargado la imagen o ya estaba descargada, el contenedor se ejecutar\u00e1, obteniendo el texto de bienvenida que se ve en el cuadro anterior.","title":"Instalaci\u00f3n"},{"location":"Sesion-1/Instalaci%C3%B3n/#configuracion-del-usuario","text":"Si estamos usando Docker en nuestro ordenador, podemos configurar nuestro usuario para usar el cliente sin tener que poner sudo delante. Para ello, debemos de ejecutar el siguiente comando: sudo usermod -aG docker $USER Para que surjan efecto los cambios, debemos de cerrar y volver a abrir la sesi\u00f3n.","title":"Configuraci\u00f3n del usuario"},{"location":"Sesion-1/Instalaci%C3%B3n/#herramientas","text":"Tambi\u00e9n es necesario tener una herramienta llamada Docker Compose. Puedes instalarla siguiendo las instrucciones que se encuentra en la p\u00e1gina de Instalaci\u00f3n de Docker Compose . Sin embargo, si usas Ubuntu o Debian, podemos instalarlo con el siguiente comando: sudo apt install docker-compose","title":"Herramientas"},{"location":"Sesion-1/Introducci%C3%B3n/","text":"\u00bfQu\u00e9 es Docker? \u00b6 Seg\u00fan Wikipedia: \u00b6 Docker es un proyecto de c\u00f3digo abierto que automatiza el despliegue de aplicaciones dentro de contenedores de software, proporcionando una capa adicional de abstracci\u00f3n y automatizaci\u00f3n de virtualizaci\u00f3n de aplicaciones en m\u00faltiples sistemas operativos. Docker utiliza caracter\u00edsticas de aislamiento de recursos del kernel Linux, tales como cgroups y espacios de nombres (namespaces) para permitir que 'contenedores' independientes se ejecuten dentro de una sola instancia de Linux, evitando la sobrecarga de iniciar y mantener m\u00e1quinas virtuales. Seg\u00fan \u201cScalable and resilient Django with Kubernetes\u201d: \u00b6 You can colloquially think of Docker containers as fat static binaries of your apps. They bundle your application code, the underlying libraries and all the necessary bits your app needs to run into a convenient package \u2014 one that can be run on a thin layer directly over the Linux kernel. What this means in practice is that you can take a container that you\u2019ve built once and run it on different versions of Linux distributions, or entirely different Linux distributions. Everything should work seamlessly. \u00bfEst\u00e1 docker virtualizado? \u00b6 En GNU/Linux Docker no es virtualizado, no hay un hipervisor. Los procesos que corren dentro de un contenedor de docker se ejecutan con el mismo kernel que la m\u00e1quina anfitri\u00f3n. Linux lo que hace es aislar esos procesos del resto de procesos del sistema, ya sean los propios de la m\u00e1quina anfitri\u00f3n o procesos de otros contenedores. Adem\u00e1s, es capaz de controlar los recursos que se le asignan a esos contenedores (cpu, memoria, red, etc.). Internamente, el contenedor no sabe que lo es y a todos los efectos es una distribuci\u00f3n GNU/Linux independiente, pero sin la penalizaci\u00f3n de rendimiento que tienen los sistemas virtualizados. As\u00ed que, cuando ejecutamos un contenedor, estamos ejecutando un servicio dentro de una distribuci\u00f3n construida a partir de una \"receta\". Esa receta permite que el sistema que se ejecuta sea siempre el mismo, independientemente de si estamos usando Docker en Ubuntu, Fedora o, incluso, sistemas privativos compatibles con Docker. De esa manera podemos garantizar que estamos desarrollando o desplegando nuestra aplicaci\u00f3n, siempre con la misma versi\u00f3n de todas las dependencias. Obviamente, si ejecutamos contenedores GNU/Linux dentro de sistemas privativos, s\u00ed habr\u00e1 virtualizaci\u00f3n. \u00bfA quien le interesa esto? \u00b6 Docker es \u00fatil a administradores de sistemas, pero tambi\u00e9n a desarrolladores. Uno de los problemas que se presentan durante el desarrollo y despliegue de aplicaciones es encontrarnos con sistemas heterog\u00e9neos, no ya entre los desarrolladores, tambi\u00e9n entre los sistemas de pruebas, pre-producci\u00f3n y producci\u00f3n. Es decir, que los desarrolladores y los sistemas donde se ejecuta la aplicaci\u00f3n tienen librer\u00edas y sistemas operativos diferentes. \u00bfY por qu\u00e9 es un problema? Pues porque la aplicaci\u00f3n puede funcionar bien en una distribuci\u00f3n de GNU/Linux pero no bien en otra, o ejecutarse bien con la versi\u00f3n de un lenguaje pero no con otra. Para asegurar la calidad de desarrollo tenemos que asegurar que todo el mundo usa las mismas versiones de todas las aplicaciones y librer\u00edas necesarios. Esto es m\u00e1s complicado de lo que parece, porque hay desarrolladores que prefieron una distribuci\u00f3n concreta, o incluso sistemas privativos. Incluso los sistemas de pruebas, pre-producci\u00f3n y producci\u00f3n suelen ser distintos. Los sistemas de producci\u00f3n suelen ser m\u00e1s nuevos y potentes y los antiguos se dejan para pruebas y pre-producci\u00f3n. Otro problema es que un mismo desarrollador o un mismo sistema de despliegue tenga que trabajar en m\u00e1s de un proyecto que requiera versiones distintas de librer\u00edas, complic\u00e1ndolo a\u00fan m\u00e1s. Docker viene a solucionar todos estos problemas, tanto para los desarrolladores como para los administradores de sistemas. Con Docker podemos crear entornos aislados con configuraciones que ser\u00e1n exactamente igual siempre. Conceptos b\u00e1sicos \u00b6 Antes de comenzar a instalar y usar docker es importante tener una serie de conceptos claros: Demonio de docker (docker daemon) : Es el proceso principal de docker. Escucha peticiones a la API y maneja los objetos de docker: im\u00e1genes, contenedores, redes, vol\u00famenes. Tambi\u00e9n es capaz de comunicarse con otros demonios para controlar servicios docker. Cliente de docker (docker client) : Es la principal herramienta que usan los administradores de sistema para interaccionar con el sistema Docker. Registro de docker (docker registry) : Es el lugar donde se almacenan las im\u00e1genes de Docker y poder descargarlas para reutilizarlas. Docker Hub es el principal registro p\u00fablico de Docker y contiene ya un mont\u00f3n de im\u00e1genes listas para ser usadas de multitud de servicios (mysql, wordpress, etc).","title":"\u00bfQu\u00e9 es Docker?"},{"location":"Sesion-1/Introducci%C3%B3n/#que-es-docker","text":"","title":"\u00bfQu\u00e9 es Docker?"},{"location":"Sesion-1/Introducci%C3%B3n/#segun-wikipedia","text":"Docker es un proyecto de c\u00f3digo abierto que automatiza el despliegue de aplicaciones dentro de contenedores de software, proporcionando una capa adicional de abstracci\u00f3n y automatizaci\u00f3n de virtualizaci\u00f3n de aplicaciones en m\u00faltiples sistemas operativos. Docker utiliza caracter\u00edsticas de aislamiento de recursos del kernel Linux, tales como cgroups y espacios de nombres (namespaces) para permitir que 'contenedores' independientes se ejecuten dentro de una sola instancia de Linux, evitando la sobrecarga de iniciar y mantener m\u00e1quinas virtuales.","title":"Seg\u00fan Wikipedia:"},{"location":"Sesion-1/Introducci%C3%B3n/#segun-scalable-and-resilient-django-with-kubernetes","text":"You can colloquially think of Docker containers as fat static binaries of your apps. They bundle your application code, the underlying libraries and all the necessary bits your app needs to run into a convenient package \u2014 one that can be run on a thin layer directly over the Linux kernel. What this means in practice is that you can take a container that you\u2019ve built once and run it on different versions of Linux distributions, or entirely different Linux distributions. Everything should work seamlessly.","title":"Seg\u00fan \u201cScalable and resilient Django with Kubernetes\u201d:"},{"location":"Sesion-1/Introducci%C3%B3n/#esta-docker-virtualizado","text":"En GNU/Linux Docker no es virtualizado, no hay un hipervisor. Los procesos que corren dentro de un contenedor de docker se ejecutan con el mismo kernel que la m\u00e1quina anfitri\u00f3n. Linux lo que hace es aislar esos procesos del resto de procesos del sistema, ya sean los propios de la m\u00e1quina anfitri\u00f3n o procesos de otros contenedores. Adem\u00e1s, es capaz de controlar los recursos que se le asignan a esos contenedores (cpu, memoria, red, etc.). Internamente, el contenedor no sabe que lo es y a todos los efectos es una distribuci\u00f3n GNU/Linux independiente, pero sin la penalizaci\u00f3n de rendimiento que tienen los sistemas virtualizados. As\u00ed que, cuando ejecutamos un contenedor, estamos ejecutando un servicio dentro de una distribuci\u00f3n construida a partir de una \"receta\". Esa receta permite que el sistema que se ejecuta sea siempre el mismo, independientemente de si estamos usando Docker en Ubuntu, Fedora o, incluso, sistemas privativos compatibles con Docker. De esa manera podemos garantizar que estamos desarrollando o desplegando nuestra aplicaci\u00f3n, siempre con la misma versi\u00f3n de todas las dependencias. Obviamente, si ejecutamos contenedores GNU/Linux dentro de sistemas privativos, s\u00ed habr\u00e1 virtualizaci\u00f3n.","title":"\u00bfEst\u00e1 docker virtualizado?"},{"location":"Sesion-1/Introducci%C3%B3n/#a-quien-le-interesa-esto","text":"Docker es \u00fatil a administradores de sistemas, pero tambi\u00e9n a desarrolladores. Uno de los problemas que se presentan durante el desarrollo y despliegue de aplicaciones es encontrarnos con sistemas heterog\u00e9neos, no ya entre los desarrolladores, tambi\u00e9n entre los sistemas de pruebas, pre-producci\u00f3n y producci\u00f3n. Es decir, que los desarrolladores y los sistemas donde se ejecuta la aplicaci\u00f3n tienen librer\u00edas y sistemas operativos diferentes. \u00bfY por qu\u00e9 es un problema? Pues porque la aplicaci\u00f3n puede funcionar bien en una distribuci\u00f3n de GNU/Linux pero no bien en otra, o ejecutarse bien con la versi\u00f3n de un lenguaje pero no con otra. Para asegurar la calidad de desarrollo tenemos que asegurar que todo el mundo usa las mismas versiones de todas las aplicaciones y librer\u00edas necesarios. Esto es m\u00e1s complicado de lo que parece, porque hay desarrolladores que prefieron una distribuci\u00f3n concreta, o incluso sistemas privativos. Incluso los sistemas de pruebas, pre-producci\u00f3n y producci\u00f3n suelen ser distintos. Los sistemas de producci\u00f3n suelen ser m\u00e1s nuevos y potentes y los antiguos se dejan para pruebas y pre-producci\u00f3n. Otro problema es que un mismo desarrollador o un mismo sistema de despliegue tenga que trabajar en m\u00e1s de un proyecto que requiera versiones distintas de librer\u00edas, complic\u00e1ndolo a\u00fan m\u00e1s. Docker viene a solucionar todos estos problemas, tanto para los desarrolladores como para los administradores de sistemas. Con Docker podemos crear entornos aislados con configuraciones que ser\u00e1n exactamente igual siempre.","title":"\u00bfA quien le interesa esto?"},{"location":"Sesion-1/Introducci%C3%B3n/#conceptos-basicos","text":"Antes de comenzar a instalar y usar docker es importante tener una serie de conceptos claros: Demonio de docker (docker daemon) : Es el proceso principal de docker. Escucha peticiones a la API y maneja los objetos de docker: im\u00e1genes, contenedores, redes, vol\u00famenes. Tambi\u00e9n es capaz de comunicarse con otros demonios para controlar servicios docker. Cliente de docker (docker client) : Es la principal herramienta que usan los administradores de sistema para interaccionar con el sistema Docker. Registro de docker (docker registry) : Es el lugar donde se almacenan las im\u00e1genes de Docker y poder descargarlas para reutilizarlas. Docker Hub es el principal registro p\u00fablico de Docker y contiene ya un mont\u00f3n de im\u00e1genes listas para ser usadas de multitud de servicios (mysql, wordpress, etc).","title":"Conceptos b\u00e1sicos"},{"location":"Sesion-2/Arquitectura/","text":"Arquitectura de Kubernetes \u00b6 Como hemos visto, un cluster de kubernetes esta formado por un nodo Master y de 2 a n nodos Worker Como vemos en la imagen, Un nodo Master se comunica con los otros nodos 1 y 2. Vamos a ver nodo por nodo cuales son las herramientas que componen la arquitectura de nuestro cluster: En nuestro nodo Master encontramos etcd , controller manager , scheduler y kube api-server . etcd : Base de datos clave-valor del cluster, para almacenar informaci\u00f3n del mismo. controller manager : Controla en todo momento el estado del cluster, para vigilar, por ejemplo, que el n\u00famero de pods desplegados sea el estimado. scheduler : Orquesta en qu\u00e9 nodo de despliega cada pod que creemos. kube api-server : expone la API de kubernetes . Esto lo hace comunicandose con el kubelet de cada nodo y con el kubectl . Ahora vamos a ver los componentes del nodo: pods : cada pod desplegado en el nodo, con sus respectivos contenedores y volumenes . kubelet : se comunica con la API de kubernetes gracias al kube api-server Otros objetos de la arquitectura de kubernetes: kubectl : interprete de comandos para terminal de kubernetes. Es la forma m\u00e1s simple de comunicarnos con la kube api. load balancer : tipo de servicio que se encarga de redirigir peticiones entre los nodos para, como su nombre indica, 'balancear la carga' y no sobrecargar nodos mientras otros no reciben tr\u00e1fico.","title":"Arquitectura de Kubernetes"},{"location":"Sesion-2/Arquitectura/#arquitectura-de-kubernetes","text":"Como hemos visto, un cluster de kubernetes esta formado por un nodo Master y de 2 a n nodos Worker Como vemos en la imagen, Un nodo Master se comunica con los otros nodos 1 y 2. Vamos a ver nodo por nodo cuales son las herramientas que componen la arquitectura de nuestro cluster: En nuestro nodo Master encontramos etcd , controller manager , scheduler y kube api-server . etcd : Base de datos clave-valor del cluster, para almacenar informaci\u00f3n del mismo. controller manager : Controla en todo momento el estado del cluster, para vigilar, por ejemplo, que el n\u00famero de pods desplegados sea el estimado. scheduler : Orquesta en qu\u00e9 nodo de despliega cada pod que creemos. kube api-server : expone la API de kubernetes . Esto lo hace comunicandose con el kubelet de cada nodo y con el kubectl . Ahora vamos a ver los componentes del nodo: pods : cada pod desplegado en el nodo, con sus respectivos contenedores y volumenes . kubelet : se comunica con la API de kubernetes gracias al kube api-server Otros objetos de la arquitectura de kubernetes: kubectl : interprete de comandos para terminal de kubernetes. Es la forma m\u00e1s simple de comunicarnos con la kube api. load balancer : tipo de servicio que se encarga de redirigir peticiones entre los nodos para, como su nombre indica, 'balancear la carga' y no sobrecargar nodos mientras otros no reciben tr\u00e1fico.","title":"Arquitectura de Kubernetes"},{"location":"Sesion-2/ConceptosBasicos/","text":"Conceptos b\u00e1sicos \u00b6 Vamos a ver algunos conceptos b\u00e1sicos que deber\u00edamos conocer: Pods \u00b6 Los Pods son la unidad m\u00ednima de Kubernetes. Cada nodo tendra de 1 a n pods, y cada uno puede tener dentro contenedores, volumenes o ambos. Estos se levantan cuando se crea un Deployment, y se encuentran como contenedores dentro de los nodos . Cada pod puede contener un contenedor, un volumen y varios mezclados. Un ejemplo claro de pod con varios contenedores seria el de una app donde en un contenedor se encuentra nuestra app y en otro nuestra base de datos. Cada pod cuenta con una IP propia dentro de nuestro equipo, lo que nos permitir\u00e1 comunicarlos entre ellos de forma organizada. Nodos \u00b6 Hace referencia a cada m\u00e1quina de nuestro cluster. Cada ordenador/servidor que use nuestro cluster ser\u00e1 un nodo. En nuestro Cluster existir\u00e1 un nodo Master y n nodos Worker. La estructura del nodo Master es distinta a la de los nodos worker que tienen todos la misma. El nodo contendr\u00e1 Pods y Volumenes, cada uno con su IP propia. Cada nodo ejecuta kubelet para comunicarse con el nodo Master, y un gestor de contenedores, Docker en la mayor\u00eda de los casos. Servicios \u00b6 Los servicios son abstracciones que nos facilitan comunicar nodos y sus respectivos pods. Por ejemplo, uno de los usos mas basicos es el de comunicar y dirigir el trafico entre pods. Esto permite que si un pod \"muere\", podamos crear una replica nueva de dicho pod y redirigir el trafico, lo que permite que la aplicaci\u00f3n no sufra el impacto de la muerte del pod. Cluster \u00b6 Como hemos dicho antes, nuestro cluster a partir de ahora va a ser nuestro 'todo'. Este estar\u00e1 compuesto por nuestros nodos Worker y el nodo Maser. Aviso El tama\u00f1o minimo de nuestro cluster debe ser de un nodo Master y dos Worker. Como podemos ver en la imagen, nuestro nodo Master es el encargado de comunicarse con los dem\u00e1s. Veremos c\u00f3mo lo hace en la seccion 'Arquitectura de Kubernetes' Despliegue \u00b6 Un controlador de Deployment proporciona actualizaciones declarativas para los Pods y los ReplicaSets. Cuando describes el estado deseado en un objeto Deployment, el controlador del Deployment se encarga de cambiar el estado actual al estado deseado de forma controlada. Puedes definir Deployments para crear nuevos ReplicaSets, o eliminar Deployments existentes y adoptar todos sus recursos con nuevos Deployments.","title":"Conceptos b\u00e1sicos"},{"location":"Sesion-2/ConceptosBasicos/#conceptos-basicos","text":"Vamos a ver algunos conceptos b\u00e1sicos que deber\u00edamos conocer:","title":"Conceptos b\u00e1sicos"},{"location":"Sesion-2/ConceptosBasicos/#pods","text":"Los Pods son la unidad m\u00ednima de Kubernetes. Cada nodo tendra de 1 a n pods, y cada uno puede tener dentro contenedores, volumenes o ambos. Estos se levantan cuando se crea un Deployment, y se encuentran como contenedores dentro de los nodos . Cada pod puede contener un contenedor, un volumen y varios mezclados. Un ejemplo claro de pod con varios contenedores seria el de una app donde en un contenedor se encuentra nuestra app y en otro nuestra base de datos. Cada pod cuenta con una IP propia dentro de nuestro equipo, lo que nos permitir\u00e1 comunicarlos entre ellos de forma organizada.","title":"Pods"},{"location":"Sesion-2/ConceptosBasicos/#nodos","text":"Hace referencia a cada m\u00e1quina de nuestro cluster. Cada ordenador/servidor que use nuestro cluster ser\u00e1 un nodo. En nuestro Cluster existir\u00e1 un nodo Master y n nodos Worker. La estructura del nodo Master es distinta a la de los nodos worker que tienen todos la misma. El nodo contendr\u00e1 Pods y Volumenes, cada uno con su IP propia. Cada nodo ejecuta kubelet para comunicarse con el nodo Master, y un gestor de contenedores, Docker en la mayor\u00eda de los casos.","title":"Nodos"},{"location":"Sesion-2/ConceptosBasicos/#servicios","text":"Los servicios son abstracciones que nos facilitan comunicar nodos y sus respectivos pods. Por ejemplo, uno de los usos mas basicos es el de comunicar y dirigir el trafico entre pods. Esto permite que si un pod \"muere\", podamos crear una replica nueva de dicho pod y redirigir el trafico, lo que permite que la aplicaci\u00f3n no sufra el impacto de la muerte del pod.","title":"Servicios"},{"location":"Sesion-2/ConceptosBasicos/#cluster","text":"Como hemos dicho antes, nuestro cluster a partir de ahora va a ser nuestro 'todo'. Este estar\u00e1 compuesto por nuestros nodos Worker y el nodo Maser. Aviso El tama\u00f1o minimo de nuestro cluster debe ser de un nodo Master y dos Worker. Como podemos ver en la imagen, nuestro nodo Master es el encargado de comunicarse con los dem\u00e1s. Veremos c\u00f3mo lo hace en la seccion 'Arquitectura de Kubernetes'","title":"Cluster"},{"location":"Sesion-2/ConceptosBasicos/#despliegue","text":"Un controlador de Deployment proporciona actualizaciones declarativas para los Pods y los ReplicaSets. Cuando describes el estado deseado en un objeto Deployment, el controlador del Deployment se encarga de cambiar el estado actual al estado deseado de forma controlada. Puedes definir Deployments para crear nuevos ReplicaSets, o eliminar Deployments existentes y adoptar todos sus recursos con nuevos Deployments.","title":"Despliegue"},{"location":"Sesion-2/Dashboard/","text":"Dashboard \u00b6 El Dashboard es una interfaz de usuario de Kubernetes basada en web. Puede utilizar su Dashboard para implementar aplicaciones en contenedores en un cl\u00faster de Kubernetes, solucionar problemas de su aplicaci\u00f3n con los contenedores y administrar los recursos del cl\u00faster. Adem\u00e1s puede utilizar su Dashboard para obtener una descripci\u00f3n general de las aplicaciones que se ejecutan en su cl\u00faster, as\u00ed como para crear o modificar recursos individuales de Kubernetes (como implementaciones, trabajos, DaemonSets, etc.). Por ejemplo, puede escalar una implementaci\u00f3n, iniciar una actualizaci\u00f3n continua, reiniciar un pod o implementar nuevas aplicaciones con un asistente de implementaci\u00f3n. El panel tambi\u00e9n proporciona informaci\u00f3n sobre el estado de los recursos de Kubernetes en su cl\u00faster y sobre cualquier error que pueda haber ocurrido. Existen distintos tipos de Dashboard que podemos utilizar para visualizar y trabajar con toda esta informaci\u00f3n. Pero los principales son: Kubernetes-Dashboard \u00b6 Rancher \u00b6 Aunque ambos ofrecen caracter\u00edsticas y funcionalidades similares. Existen algunas diferencias que debemos de tener en cuenta ya que pueden hacer que nos decantemos por uno u otro a la hora de administrar nuestro servidor. Profundizaremos m\u00e1s sobre ellas en el siguiente ejemplo.","title":"Dashboard"},{"location":"Sesion-2/Dashboard/#dashboard","text":"El Dashboard es una interfaz de usuario de Kubernetes basada en web. Puede utilizar su Dashboard para implementar aplicaciones en contenedores en un cl\u00faster de Kubernetes, solucionar problemas de su aplicaci\u00f3n con los contenedores y administrar los recursos del cl\u00faster. Adem\u00e1s puede utilizar su Dashboard para obtener una descripci\u00f3n general de las aplicaciones que se ejecutan en su cl\u00faster, as\u00ed como para crear o modificar recursos individuales de Kubernetes (como implementaciones, trabajos, DaemonSets, etc.). Por ejemplo, puede escalar una implementaci\u00f3n, iniciar una actualizaci\u00f3n continua, reiniciar un pod o implementar nuevas aplicaciones con un asistente de implementaci\u00f3n. El panel tambi\u00e9n proporciona informaci\u00f3n sobre el estado de los recursos de Kubernetes en su cl\u00faster y sobre cualquier error que pueda haber ocurrido. Existen distintos tipos de Dashboard que podemos utilizar para visualizar y trabajar con toda esta informaci\u00f3n. Pero los principales son:","title":"Dashboard"},{"location":"Sesion-2/Dashboard/#kubernetes-dashboard","text":"","title":"Kubernetes-Dashboard"},{"location":"Sesion-2/Dashboard/#rancher","text":"Aunque ambos ofrecen caracter\u00edsticas y funcionalidades similares. Existen algunas diferencias que debemos de tener en cuenta ya que pueden hacer que nos decantemos por uno u otro a la hora de administrar nuestro servidor. Profundizaremos m\u00e1s sobre ellas en el siguiente ejemplo.","title":"Rancher"},{"location":"Sesion-2/EjemploDeployment/","text":"Ejemplo de deployment \u00b6 Como sabemos, para trabajar con kubernetes necesitamos un cluster con dos nodos Worker y un nodo Master del que no disponemos. Por eso, para practicar en nuestro ordenador, vamos a utilizar Minikube . Minikube nos permite simular en nuestro equipo un cluster entero con su nodo Master y un nodo worker. Podemos inicializarlo de la siguiente manera: minikube start Esto har\u00e1 que minikube empiece a funcionar, simulando asi nuestro entorno de prueba local. Ahora lo que vamos a hacer es clonar el repositorio de la App que queremos levantar. En este caso vamos a utilizar la 'Pokeapp', una Appweb de Pokemon desarrollada en Angular por Antonio Moruno (compa\u00f1ero del grado de informatica en la UCO y delegado en el Aula de Software Libre). git clone https://github.com/moruno21/pokeapp Clonamos el repositorio a nuestro directorio de trabajo (el escritorio por ejemplo). Ahora vamos a crear un Dockerfile que nos genere la imagen que necesitamos: $ cat Dockerfile ### STAGE 1 FROM node:10-alpine as build-step RUN mkdir -p /app WORKDIR /app COPY package.json /app RUN npm install COPY ./ /app RUN npm run build --prod ### STAGE 2 FROM nginx:1.17.1-alpine COPY --from=build-step /app/dist/pokeapi/ /usr/share/nginx/html Con este Dockerfile podremos genera la imagen que usar\u00e1n nuestros contenedores de la siguiente forma: docker build -t pokeapp-image . Hemos generado nuestra imagen y podemos comprobarlo haciendo $ docker images Ahora creamos nuestro pokedeploy.yaml y nuestro pokeloadbalancer.yaml . $ cat pokedeployment.yaml apiVersion: apps/v1 kind: Deployment metadata: creationTimestamp: null labels: app: pokeapp name: pokeapp spec: replicas: 5 selector: matchLabels: app: pokeapp strategy: {} template: metadata: creationTimestamp: null labels: app: pokeapp spec: containers: - name: pokeapp image: docker.io/jdes01/pokeimage imagePullPolicy: IfNotPresent resources: {} ports: - containerPort: 80 status: {} Con esto creamos un deployment en el que levantaremos 5 replicas (5 pods) que se comunicaran a traves del puerto 80 y que contendran uno de nuestros contenedores (cuya imagen creamos con el Dockerfile). Ahora hacemos el pokeloadbalancer.yaml : $ cat pokeloadbalancer.yaml apiVersion: v1 kind: Service metadata: name: pokeapp-loadbalancer labels: run: pokeapp spec: type: LoadBalancer ports: - name: \"80\" port: 80 targetPort: 80 protocol: TCP selector: app: pokeapp Este ser\u00e1 nuestro principal servicio. Redistribuir\u00e1 el tr\u00e1fico que sostenga nuestra aplicacion, \"balanceando la carga\" de los pods para no saturarlos. Ahora que hemos desplegado nuestros pods, cuyo estado comprobamos con kubectl get pods Y nuestro servicio, que podemos ver con kubectl get services Podemos decir que ya hemos conpletado el deploy de nuestra app. De igual forma, podemos ver informacion del mismo con: kubectl get deployments Al tratarse de un ejemplo ejecutado en un cluster de prueba, expondremos nuestro cluster usando minikube tunnel Ahora, si volvemos a ejecutar kubectl get services veremos que a nuestro pokeLoadBalancer se le ha asignado una IP externa. Podemos escribirla en nuestro navegador y comprobar que esta desplegada. Con un servicio de DNS y un dominio podriamos hacer que cualquier persona la buscase.","title":"Ejemplo de deployment"},{"location":"Sesion-2/EjemploDeployment/#ejemplo-de-deployment","text":"Como sabemos, para trabajar con kubernetes necesitamos un cluster con dos nodos Worker y un nodo Master del que no disponemos. Por eso, para practicar en nuestro ordenador, vamos a utilizar Minikube . Minikube nos permite simular en nuestro equipo un cluster entero con su nodo Master y un nodo worker. Podemos inicializarlo de la siguiente manera: minikube start Esto har\u00e1 que minikube empiece a funcionar, simulando asi nuestro entorno de prueba local. Ahora lo que vamos a hacer es clonar el repositorio de la App que queremos levantar. En este caso vamos a utilizar la 'Pokeapp', una Appweb de Pokemon desarrollada en Angular por Antonio Moruno (compa\u00f1ero del grado de informatica en la UCO y delegado en el Aula de Software Libre). git clone https://github.com/moruno21/pokeapp Clonamos el repositorio a nuestro directorio de trabajo (el escritorio por ejemplo). Ahora vamos a crear un Dockerfile que nos genere la imagen que necesitamos: $ cat Dockerfile ### STAGE 1 FROM node:10-alpine as build-step RUN mkdir -p /app WORKDIR /app COPY package.json /app RUN npm install COPY ./ /app RUN npm run build --prod ### STAGE 2 FROM nginx:1.17.1-alpine COPY --from=build-step /app/dist/pokeapi/ /usr/share/nginx/html Con este Dockerfile podremos genera la imagen que usar\u00e1n nuestros contenedores de la siguiente forma: docker build -t pokeapp-image . Hemos generado nuestra imagen y podemos comprobarlo haciendo $ docker images Ahora creamos nuestro pokedeploy.yaml y nuestro pokeloadbalancer.yaml . $ cat pokedeployment.yaml apiVersion: apps/v1 kind: Deployment metadata: creationTimestamp: null labels: app: pokeapp name: pokeapp spec: replicas: 5 selector: matchLabels: app: pokeapp strategy: {} template: metadata: creationTimestamp: null labels: app: pokeapp spec: containers: - name: pokeapp image: docker.io/jdes01/pokeimage imagePullPolicy: IfNotPresent resources: {} ports: - containerPort: 80 status: {} Con esto creamos un deployment en el que levantaremos 5 replicas (5 pods) que se comunicaran a traves del puerto 80 y que contendran uno de nuestros contenedores (cuya imagen creamos con el Dockerfile). Ahora hacemos el pokeloadbalancer.yaml : $ cat pokeloadbalancer.yaml apiVersion: v1 kind: Service metadata: name: pokeapp-loadbalancer labels: run: pokeapp spec: type: LoadBalancer ports: - name: \"80\" port: 80 targetPort: 80 protocol: TCP selector: app: pokeapp Este ser\u00e1 nuestro principal servicio. Redistribuir\u00e1 el tr\u00e1fico que sostenga nuestra aplicacion, \"balanceando la carga\" de los pods para no saturarlos. Ahora que hemos desplegado nuestros pods, cuyo estado comprobamos con kubectl get pods Y nuestro servicio, que podemos ver con kubectl get services Podemos decir que ya hemos conpletado el deploy de nuestra app. De igual forma, podemos ver informacion del mismo con: kubectl get deployments Al tratarse de un ejemplo ejecutado en un cluster de prueba, expondremos nuestro cluster usando minikube tunnel Ahora, si volvemos a ejecutar kubectl get services veremos que a nuestro pokeLoadBalancer se le ha asignado una IP externa. Podemos escribirla en nuestro navegador y comprobar que esta desplegada. Con un servicio de DNS y un dominio podriamos hacer que cualquier persona la buscase.","title":"Ejemplo de deployment"},{"location":"Sesion-2/Herramientas/","text":"Herramientas \u00b6 Kubernetes fue dise\u00f1ada como una plataforma: para poder construir un ecosistema de componentes y herramientas que hacen m\u00e1s f\u00e1cil el desplegar, escalar y administrar aplicaciones. Este ecosistema ofrece muchas funcionalidades entre las cuales destacan: Kubectl \u00b6 Usando kubectl, puedes inspeccionar recursos del cl\u00faster; crear, eliminar y actualizar componentes; Para m\u00e1s informaci\u00f3n: https://kubernetes.io/kubectl/ Kind \u00b6 Kind le permite usar Kubernetes en su m\u00e1quina local. Para m\u00e1s informaci\u00f3n: https://kubernetes.io/kind/ MiniKube \u00b6 Minikube es una herramienta que le permite usar Kubernetes en su m\u00e1quina local. minikube le permite ejecutar un \u00fanico nodo en su computadora personal para que pueda probar Kubernetes Para m\u00e1s informaci\u00f3n: https://kubernetes.io/minikube/ Kubeadm \u00b6 Tambi\u00e9n se puede utilizar kubeadm para crear y gestionar cl\u00fasteres de Kubernetes Para m\u00e1s informaci\u00f3n: https://kubernetes.io/kubeadm/","title":"Herramientas"},{"location":"Sesion-2/Herramientas/#herramientas","text":"Kubernetes fue dise\u00f1ada como una plataforma: para poder construir un ecosistema de componentes y herramientas que hacen m\u00e1s f\u00e1cil el desplegar, escalar y administrar aplicaciones. Este ecosistema ofrece muchas funcionalidades entre las cuales destacan:","title":"Herramientas"},{"location":"Sesion-2/Herramientas/#kubectl","text":"Usando kubectl, puedes inspeccionar recursos del cl\u00faster; crear, eliminar y actualizar componentes; Para m\u00e1s informaci\u00f3n: https://kubernetes.io/kubectl/","title":"Kubectl"},{"location":"Sesion-2/Herramientas/#kind","text":"Kind le permite usar Kubernetes en su m\u00e1quina local. Para m\u00e1s informaci\u00f3n: https://kubernetes.io/kind/","title":"Kind"},{"location":"Sesion-2/Herramientas/#minikube","text":"Minikube es una herramienta que le permite usar Kubernetes en su m\u00e1quina local. minikube le permite ejecutar un \u00fanico nodo en su computadora personal para que pueda probar Kubernetes Para m\u00e1s informaci\u00f3n: https://kubernetes.io/minikube/","title":"MiniKube"},{"location":"Sesion-2/Herramientas/#kubeadm","text":"Tambi\u00e9n se puede utilizar kubeadm para crear y gestionar cl\u00fasteres de Kubernetes Para m\u00e1s informaci\u00f3n: https://kubernetes.io/kubeadm/","title":"Kubeadm"},{"location":"Sesion-2/Introducci%C3%B3n/","text":"\u00bfQu\u00e9 es Kubernetes? \u00b6 Introducci\u00f3n \u00b6 Kubernetes v1.0 fue liberada el 21 de julio de 2015. Fue originalmente dise\u00f1ado por Google y donado a la Cloud Native Computing Foundation (parte de la Linux Foundation). Se trata de un sistema de c\u00f3digo libre para la automatizaci\u00f3n del despliegue, ajuste de escala y manejo de aplicaciones en contenedores. Soporta diferentes entornos para la ejecuci\u00f3n de contenedores, incluido Docker el cual vimos en la sesi\u00f3n anterior. Actualmente se utiliza en multitud de proyectos y empresas entre las cuales destaca: Rancher Labs en su plataforma de mejoramiento de contenedores Rancher\u200b. Red Hat para su producto OpenShift\u200b CoreOS para su producto Tectonic IBM para su producto IBM Spectrum Conductor for Containers.","title":"\u00bfQu\u00e9 es Kubernetes?"},{"location":"Sesion-2/Introducci%C3%B3n/#que-es-kubernetes","text":"","title":"\u00bfQu\u00e9 es Kubernetes?"},{"location":"Sesion-2/Introducci%C3%B3n/#introduccion","text":"Kubernetes v1.0 fue liberada el 21 de julio de 2015. Fue originalmente dise\u00f1ado por Google y donado a la Cloud Native Computing Foundation (parte de la Linux Foundation). Se trata de un sistema de c\u00f3digo libre para la automatizaci\u00f3n del despliegue, ajuste de escala y manejo de aplicaciones en contenedores. Soporta diferentes entornos para la ejecuci\u00f3n de contenedores, incluido Docker el cual vimos en la sesi\u00f3n anterior. Actualmente se utiliza en multitud de proyectos y empresas entre las cuales destaca: Rancher Labs en su plataforma de mejoramiento de contenedores Rancher\u200b. Red Hat para su producto OpenShift\u200b CoreOS para su producto Tectonic IBM para su producto IBM Spectrum Conductor for Containers.","title":"Introducci\u00f3n"},{"location":"Sesion-2/Kubectl/","text":"Kubectl \u00b6 A trav\u00e9s de la herramienta de l\u00ednea de comandos kubectl podemos controlar nuestors cl\u00fasters de Kubernetes. La configuraci\u00f3n de kubectl reside en el archivo config que se encuentra en el directorio $HOME/.kube Aunque si queremos, tambi\u00e9n podemos especificar otros archivos kubeconfig configurando la variable de entorno KUBECONFIG o configurando la bandera --kubeconfig flag.. Sintaxis \u00b6 Los comandos de Kubectl tienen el siguiente formato: kubectl [ command ] [ TYPE ] [ NAME ] [ flags ] Donde command , TYPE , NAME , y flags son: command : Operaci\u00f3n que se desea realizar sobre uno o m\u00e1s recursos. Por ejemplo: create , get , describe , delete . TYPE : Indica el tipo de recurso al que se le aplica la operaci\u00f3n. Los tipos de recursos son insensibles a las may\u00fasculas y se pueden indicar tanto en singular, plural o incluso de forma abreviada. Por ejemplo los siguientes comandos producen la misma salida: kubectl get pod pod1 kubectl get pods pod1 kubectl get po pod1 NAME : Hace referencia al nombre del recurso al que se le va a aplicar dicha operaci\u00f3n. Los nombres son sensibles a las may\u00fasculas. Y si lo omitimos, se nos mostrar\u00e1 la informaci\u00f3n de todos los recursos disponibles. Por ejemplo: kubectl get pods . Al realizar una operaci\u00f3n en varios recursos, puede especificar cada recurso por tipo y nombre o especificar uno o m\u00e1s archivos: Para especificar recursos por tipo y nombre: Agrupar recursos si son del mismo tipo: TYPE1 name1 name2 name<#> . Ejemplo: kubectl get pod example-pod1 example-pod2 Especificar distintos tipos de recursos individualmente: TYPE1/name1 TYPE1/name2 TYPE2/name3 TYPE<#>/name<#> . Ejemplo: kubectl get pod/example-pod1 replicationcontroller/example-rc1 Especificar recursos con uno o m\u00e1s archivos: -f file1 -f file2 -f file<#> Utilice YAML mejor que JSON ya que YAML suele ser m\u00e1s user-friendly, sobretodo para ficheros de configuraci\u00f3n. Ejemplo: kubectl get -f ./pod.yaml flags : Permite especificar banderas. Por ejemplo, puede utilizar las banderas -s o --server para especificar la direcci\u00f3n y el puerto a la API de Kubernetes. Atenci\u00f3n Las banderas que especifiquemos a trav\u00e9s de la linea de comandos anula los valores predeterminados de las banderas y las variables de entorno correspondientes. Si necesitas ayuda escribe kubectl help en la consola. Operaciones \u00b6 La siguiente tabla incluye una breve descripi\u00f3n y la sintaxis general de las operaciones de kubectl : Operation Syntax Description alpha kubectl alpha SUBCOMMAND [flags] List the available commands that correspond to alpha features, which are not enabled in Kubernetes clusters by default. annotate kubectl annotate (-f FILENAME | TYPE NAME | TYPE/NAME) KEY_1=VAL_1 ... KEY_N=VAL_N [--overwrite] [--all] [--resource-version=version] [flags] Add or update the annotations of one or more resources. api-resources kubectl api-resources [flags] List the API resources that are available. api-versions kubectl api-versions [flags] List the API versions that are available. apply kubectl apply -f FILENAME [flags] Apply a configuration change to a resource from a file or stdin. attach kubectl attach POD -c CONTAINER [-i] [-t] [flags] Attach to a running container either to view the output stream or interact with the container (stdin). auth kubectl auth [flags] [options] Inspect authorization. autoscale kubectl autoscale (-f FILENAME | TYPE NAME | TYPE/NAME) [--min=MINPODS] --max=MAXPODS [--cpu-percent=CPU] [flags] Automatically scale the set of pods that are managed by a replication controller. certificate kubectl certificate SUBCOMMAND [options] Modify certificate resources. cluster-info kubectl cluster-info [flags] Display endpoint information about the master and services in the cluster. completion kubectl completion SHELL [options] Output shell completion code for the specified shell (bash or zsh). config kubectl config SUBCOMMAND [flags] Modifies kubeconfig files. See the individual subcommands for details. convert kubectl convert -f FILENAME [options] Convert config files between different API versions. Both YAML and JSON formats are accepted. cordon kubectl cordon NODE [options] Mark node as unschedulable. cp kubectl cp <file-spec-src> <file-spec-dest> [options] Copy files and directories to and from containers. create kubectl create -f FILENAME [flags] Create one or more resources from a file or stdin. delete kubectl delete (-f FILENAME | TYPE [NAME | /NAME | -l label | --all]) [flags] Delete resources either from a file, stdin, or specifying label selectors, names, resource selectors, or resources. describe kubectl describe (-f FILENAME | TYPE [NAME_PREFIX | /NAME | -l label]) [flags] Display the detailed state of one or more resources. diff kubectl diff -f FILENAME [flags] Diff file or stdin against live configuration. drain kubectl drain NODE [options] Drain node in preparation for maintenance. edit kubectl edit (-f FILENAME | TYPE NAME | TYPE/NAME) [flags] Edit and update the definition of one or more resources on the server by using the default editor. exec kubectl exec POD [-c CONTAINER] [-i] [-t] [flags] [-- COMMAND [args...]] Execute a command against a container in a pod. explain kubectl explain [--recursive=false] [flags] Get documentation of various resources. For instance pods, nodes, services, etc. expose kubectl expose (-f FILENAME | TYPE NAME | TYPE/NAME) [--port=port] [--protocol=TCP|UDP] [--target-port=number-or-name] [--name=name] [--external-ip=external-ip-of-service] [--type=type] [flags] Expose a replication controller, service, or pod as a new Kubernetes service. get kubectl get (-f FILENAME | TYPE [NAME | /NAME | -l label]) [--watch] [--sort-by=FIELD] [[-o | --output]=OUTPUT_FORMAT] [flags] List one or more resources. kustomize kubectl kustomize <dir> [flags] [options] List a set of API resources generated from instructions in a kustomization.yaml file. The argument must be the path to the directory containing the file, or a git repository URL with a path suffix specifying same with respect to the repository root. label kubectl label (-f FILENAME | TYPE NAME | TYPE/NAME) KEY_1=VAL_1 ... KEY_N=VAL_N [--overwrite] [--all] [--resource-version=version] [flags] Add or update the labels of one or more resources. logs kubectl logs POD [-c CONTAINER] [--follow] [flags] Print the logs for a container in a pod. options kubectl options List of global command-line options, which apply to all commands. patch kubectl patch (-f FILENAME | TYPE NAME | TYPE/NAME) --patch PATCH [flags] Update one or more fields of a resource by using the strategic merge patch process. plugin kubectl plugin [flags] [options] Provides utilities for interacting with plugins. port-forward kubectl port-forward POD [LOCAL_PORT:]REMOTE_PORT [...[LOCAL_PORT_N:]REMOTE_PORT_N] [flags] Forward one or more local ports to a pod. proxy kubectl proxy [--port=PORT] [--www=static-dir] [--www-prefix=prefix] [--api-prefix=prefix] [flags] Run a proxy to the Kubernetes API server. replace kubectl replace -f FILENAME Replace a resource from a file or stdin. rollout kubectl rollout SUBCOMMAND [options] Manage the rollout of a resource. Valid resource types include: deployments, daemonsets and statefulsets. run kubectl run NAME --image=image [--env=\"key=value\"] [--port=port] [--dry-run=server|client|none] [--overrides=inline-json] [flags] Run a specified image on the cluster. scale kubectl scale (-f FILENAME | TYPE NAME | TYPE/NAME) --replicas=COUNT [--resource-version=version] [--current-replicas=count] [flags] Update the size of the specified replication controller. set kubectl set SUBCOMMAND [options] Configure application resources. taint kubectl taint NODE NAME KEY_1=VAL_1:TAINT_EFFECT_1 ... KEY_N=VAL_N:TAINT_EFFECT_N [options] Update the taints on one or more nodes. top kubectl top [flags] [options] Display Resource (CPU/Memory/Storage) usage. uncordon kubectl uncordon NODE [options] Mark node as schedulable. version kubectl version [--client] [flags] Display the Kubernetes version running on the client and server. wait kubectl wait ([-f FILENAME] | resource.group/resource.name | resource.group [(-l label | --all)]) [--for=delete|--for condition=available] [options] Experimental: Wait for a specific condition on one or many resources. Para m\u00e1s informaci\u00f3n visite la documentaci\u00f3n de kubectl","title":"Kubectl"},{"location":"Sesion-2/Kubectl/#kubectl","text":"A trav\u00e9s de la herramienta de l\u00ednea de comandos kubectl podemos controlar nuestors cl\u00fasters de Kubernetes. La configuraci\u00f3n de kubectl reside en el archivo config que se encuentra en el directorio $HOME/.kube Aunque si queremos, tambi\u00e9n podemos especificar otros archivos kubeconfig configurando la variable de entorno KUBECONFIG o configurando la bandera --kubeconfig flag..","title":"Kubectl"},{"location":"Sesion-2/Kubectl/#sintaxis","text":"Los comandos de Kubectl tienen el siguiente formato: kubectl [ command ] [ TYPE ] [ NAME ] [ flags ] Donde command , TYPE , NAME , y flags son: command : Operaci\u00f3n que se desea realizar sobre uno o m\u00e1s recursos. Por ejemplo: create , get , describe , delete . TYPE : Indica el tipo de recurso al que se le aplica la operaci\u00f3n. Los tipos de recursos son insensibles a las may\u00fasculas y se pueden indicar tanto en singular, plural o incluso de forma abreviada. Por ejemplo los siguientes comandos producen la misma salida: kubectl get pod pod1 kubectl get pods pod1 kubectl get po pod1 NAME : Hace referencia al nombre del recurso al que se le va a aplicar dicha operaci\u00f3n. Los nombres son sensibles a las may\u00fasculas. Y si lo omitimos, se nos mostrar\u00e1 la informaci\u00f3n de todos los recursos disponibles. Por ejemplo: kubectl get pods . Al realizar una operaci\u00f3n en varios recursos, puede especificar cada recurso por tipo y nombre o especificar uno o m\u00e1s archivos: Para especificar recursos por tipo y nombre: Agrupar recursos si son del mismo tipo: TYPE1 name1 name2 name<#> . Ejemplo: kubectl get pod example-pod1 example-pod2 Especificar distintos tipos de recursos individualmente: TYPE1/name1 TYPE1/name2 TYPE2/name3 TYPE<#>/name<#> . Ejemplo: kubectl get pod/example-pod1 replicationcontroller/example-rc1 Especificar recursos con uno o m\u00e1s archivos: -f file1 -f file2 -f file<#> Utilice YAML mejor que JSON ya que YAML suele ser m\u00e1s user-friendly, sobretodo para ficheros de configuraci\u00f3n. Ejemplo: kubectl get -f ./pod.yaml flags : Permite especificar banderas. Por ejemplo, puede utilizar las banderas -s o --server para especificar la direcci\u00f3n y el puerto a la API de Kubernetes. Atenci\u00f3n Las banderas que especifiquemos a trav\u00e9s de la linea de comandos anula los valores predeterminados de las banderas y las variables de entorno correspondientes. Si necesitas ayuda escribe kubectl help en la consola.","title":"Sintaxis"},{"location":"Sesion-2/Kubectl/#operaciones","text":"La siguiente tabla incluye una breve descripi\u00f3n y la sintaxis general de las operaciones de kubectl : Operation Syntax Description alpha kubectl alpha SUBCOMMAND [flags] List the available commands that correspond to alpha features, which are not enabled in Kubernetes clusters by default. annotate kubectl annotate (-f FILENAME | TYPE NAME | TYPE/NAME) KEY_1=VAL_1 ... KEY_N=VAL_N [--overwrite] [--all] [--resource-version=version] [flags] Add or update the annotations of one or more resources. api-resources kubectl api-resources [flags] List the API resources that are available. api-versions kubectl api-versions [flags] List the API versions that are available. apply kubectl apply -f FILENAME [flags] Apply a configuration change to a resource from a file or stdin. attach kubectl attach POD -c CONTAINER [-i] [-t] [flags] Attach to a running container either to view the output stream or interact with the container (stdin). auth kubectl auth [flags] [options] Inspect authorization. autoscale kubectl autoscale (-f FILENAME | TYPE NAME | TYPE/NAME) [--min=MINPODS] --max=MAXPODS [--cpu-percent=CPU] [flags] Automatically scale the set of pods that are managed by a replication controller. certificate kubectl certificate SUBCOMMAND [options] Modify certificate resources. cluster-info kubectl cluster-info [flags] Display endpoint information about the master and services in the cluster. completion kubectl completion SHELL [options] Output shell completion code for the specified shell (bash or zsh). config kubectl config SUBCOMMAND [flags] Modifies kubeconfig files. See the individual subcommands for details. convert kubectl convert -f FILENAME [options] Convert config files between different API versions. Both YAML and JSON formats are accepted. cordon kubectl cordon NODE [options] Mark node as unschedulable. cp kubectl cp <file-spec-src> <file-spec-dest> [options] Copy files and directories to and from containers. create kubectl create -f FILENAME [flags] Create one or more resources from a file or stdin. delete kubectl delete (-f FILENAME | TYPE [NAME | /NAME | -l label | --all]) [flags] Delete resources either from a file, stdin, or specifying label selectors, names, resource selectors, or resources. describe kubectl describe (-f FILENAME | TYPE [NAME_PREFIX | /NAME | -l label]) [flags] Display the detailed state of one or more resources. diff kubectl diff -f FILENAME [flags] Diff file or stdin against live configuration. drain kubectl drain NODE [options] Drain node in preparation for maintenance. edit kubectl edit (-f FILENAME | TYPE NAME | TYPE/NAME) [flags] Edit and update the definition of one or more resources on the server by using the default editor. exec kubectl exec POD [-c CONTAINER] [-i] [-t] [flags] [-- COMMAND [args...]] Execute a command against a container in a pod. explain kubectl explain [--recursive=false] [flags] Get documentation of various resources. For instance pods, nodes, services, etc. expose kubectl expose (-f FILENAME | TYPE NAME | TYPE/NAME) [--port=port] [--protocol=TCP|UDP] [--target-port=number-or-name] [--name=name] [--external-ip=external-ip-of-service] [--type=type] [flags] Expose a replication controller, service, or pod as a new Kubernetes service. get kubectl get (-f FILENAME | TYPE [NAME | /NAME | -l label]) [--watch] [--sort-by=FIELD] [[-o | --output]=OUTPUT_FORMAT] [flags] List one or more resources. kustomize kubectl kustomize <dir> [flags] [options] List a set of API resources generated from instructions in a kustomization.yaml file. The argument must be the path to the directory containing the file, or a git repository URL with a path suffix specifying same with respect to the repository root. label kubectl label (-f FILENAME | TYPE NAME | TYPE/NAME) KEY_1=VAL_1 ... KEY_N=VAL_N [--overwrite] [--all] [--resource-version=version] [flags] Add or update the labels of one or more resources. logs kubectl logs POD [-c CONTAINER] [--follow] [flags] Print the logs for a container in a pod. options kubectl options List of global command-line options, which apply to all commands. patch kubectl patch (-f FILENAME | TYPE NAME | TYPE/NAME) --patch PATCH [flags] Update one or more fields of a resource by using the strategic merge patch process. plugin kubectl plugin [flags] [options] Provides utilities for interacting with plugins. port-forward kubectl port-forward POD [LOCAL_PORT:]REMOTE_PORT [...[LOCAL_PORT_N:]REMOTE_PORT_N] [flags] Forward one or more local ports to a pod. proxy kubectl proxy [--port=PORT] [--www=static-dir] [--www-prefix=prefix] [--api-prefix=prefix] [flags] Run a proxy to the Kubernetes API server. replace kubectl replace -f FILENAME Replace a resource from a file or stdin. rollout kubectl rollout SUBCOMMAND [options] Manage the rollout of a resource. Valid resource types include: deployments, daemonsets and statefulsets. run kubectl run NAME --image=image [--env=\"key=value\"] [--port=port] [--dry-run=server|client|none] [--overrides=inline-json] [flags] Run a specified image on the cluster. scale kubectl scale (-f FILENAME | TYPE NAME | TYPE/NAME) --replicas=COUNT [--resource-version=version] [--current-replicas=count] [flags] Update the size of the specified replication controller. set kubectl set SUBCOMMAND [options] Configure application resources. taint kubectl taint NODE NAME KEY_1=VAL_1:TAINT_EFFECT_1 ... KEY_N=VAL_N:TAINT_EFFECT_N [options] Update the taints on one or more nodes. top kubectl top [flags] [options] Display Resource (CPU/Memory/Storage) usage. uncordon kubectl uncordon NODE [options] Mark node as schedulable. version kubectl version [--client] [flags] Display the Kubernetes version running on the client and server. wait kubectl wait ([-f FILENAME] | resource.group/resource.name | resource.group [(-l label | --all)]) [--for=delete|--for condition=available] [options] Experimental: Wait for a specific condition on one or many resources. Para m\u00e1s informaci\u00f3n visite la documentaci\u00f3n de kubectl","title":"Operaciones"},{"location":"Sesion-2/MiniKube/","text":"Pr\u00e1ctica \u00b6 Ahora que ya conocemos el funcionamiento de kubernetes llega el momento de afianzar estos conocimientos realizando una peque\u00f1a pr\u00e1ctica. Para ello haremos uso de una de las herramientas mencionadas anteriormente: MiniKube. Esta nos permitir\u00e1 levantar un nodo en nuestra m\u00e1quina para que podamos empezar a trabajar con Kubernetes. Requisitos m\u00ednimos: \u00b6 Dual-Core CPU o superior 2GB de RAM 20 GB de espacio libre en disco Conexi\u00f3n a Internet Administrador de contenedores o m\u00e1quinas virtuales, como: Docker, Hyperkit, Hyper-V, KVM, Parallels, Podman, VirtualBox o VMWare Si tu equipo no cuenta con los recursos suficientes para ejecutar MiniKube o no quieres instalarlo en tu ordenador personal, no te preocupes puedes seguir igualmente el tutorial desde la web de MiniKube donde dispones de todas las instrucciones paso a paso y adm\u00e1s cuentas con una consola virtual para realizar el tutorial. Enlace al tutorial: \u00b6 Hello Minikube Otros cursos y gu\u00edas: \u00b6 Kubernetes Introduction Extending Kubernetes Orchestration & Application Definition","title":"Pr\u00e1ctica"},{"location":"Sesion-2/MiniKube/#practica","text":"Ahora que ya conocemos el funcionamiento de kubernetes llega el momento de afianzar estos conocimientos realizando una peque\u00f1a pr\u00e1ctica. Para ello haremos uso de una de las herramientas mencionadas anteriormente: MiniKube. Esta nos permitir\u00e1 levantar un nodo en nuestra m\u00e1quina para que podamos empezar a trabajar con Kubernetes.","title":"Pr\u00e1ctica"},{"location":"Sesion-2/MiniKube/#requisitos-minimos","text":"Dual-Core CPU o superior 2GB de RAM 20 GB de espacio libre en disco Conexi\u00f3n a Internet Administrador de contenedores o m\u00e1quinas virtuales, como: Docker, Hyperkit, Hyper-V, KVM, Parallels, Podman, VirtualBox o VMWare Si tu equipo no cuenta con los recursos suficientes para ejecutar MiniKube o no quieres instalarlo en tu ordenador personal, no te preocupes puedes seguir igualmente el tutorial desde la web de MiniKube donde dispones de todas las instrucciones paso a paso y adm\u00e1s cuentas con una consola virtual para realizar el tutorial.","title":"Requisitos m\u00ednimos:"},{"location":"Sesion-2/MiniKube/#enlace-al-tutorial","text":"Hello Minikube","title":"Enlace al tutorial:"},{"location":"Sesion-2/MiniKube/#otros-cursos-y-guias","text":"Kubernetes Introduction Extending Kubernetes Orchestration & Application Definition","title":"Otros cursos y gu\u00edas:"},{"location":"Sesion-2/Servicios/","text":"Tipos de servicios \u00b6 ClusterIP: \u00b6 El servicio toma una IP interna del cluster y hace que dicho servicio solo sea accesible a traves del cluster. $ cat clusterIP-service.yaml apiVersion: v1 kind: Service metadata: name: my-internal-service spec: selector: app: my-app type: ClusterIP ports: - name: http port: 80 targetPort: 80 protocol: TCP NodePort: \u00b6 Expone el servicio a cada Nodo a traves de la IP de estos. $ cat nodePort-service.yaml kind: Service metadata: name: my-nodeport-service spec: selector: app: my-app type: NodePort ports: - name: http port: 80 targetPort: 80 nodePort: 30036 protocol: TCP Load Balancer: \u00b6 Expone el servicio de forma externa utilizando un balanceador (cloud, si se puede) y genera automaticamente un NodePort y un ClusterIP. $ cat loadBalancer-service.yaml apiVersion: extensions/v1beta1 kind: Ingress metadata: name: my-ingress spec: backend: serviceName: other servicePort: 8080 rules: - host: foo.mydomain.com http: paths: - backend: serviceName: foo servicePort: 8080 - host: mydomain.com http: paths: - path: /bar/* backend: serviceName: bar servicePort: 8080 ExternalName: \u00b6 Mapea el servicio al exterior con un nombre definido. $ cat externalName-service.yaml apiVersion: extensions/v1beta1 kind: Service apiVersion: v1 metadata: name: my-service spec: type: ExternalName externalName: my.service.example.com Ingress: \u00b6 No es un servicio como tal, actua como un 'enrutador de servicios' $ cat ingress.yaml apiVersion: extensions/v1beta1 kind: Ingress metadata: name: my-ingress spec: backend: serviceName: other servicePort: 8080 rules: - host: foo.mydomain.com http: paths: - backend: serviceName: foo servicePort: 8080 - host: mydomain.com http: paths: - path: /bar/* backend: serviceName: bar servicePort: 8080","title":"Tipos de servicios"},{"location":"Sesion-2/Servicios/#tipos-de-servicios","text":"","title":"Tipos de servicios"},{"location":"Sesion-2/Servicios/#clusterip","text":"El servicio toma una IP interna del cluster y hace que dicho servicio solo sea accesible a traves del cluster. $ cat clusterIP-service.yaml apiVersion: v1 kind: Service metadata: name: my-internal-service spec: selector: app: my-app type: ClusterIP ports: - name: http port: 80 targetPort: 80 protocol: TCP","title":"ClusterIP:"},{"location":"Sesion-2/Servicios/#nodeport","text":"Expone el servicio a cada Nodo a traves de la IP de estos. $ cat nodePort-service.yaml kind: Service metadata: name: my-nodeport-service spec: selector: app: my-app type: NodePort ports: - name: http port: 80 targetPort: 80 nodePort: 30036 protocol: TCP","title":"NodePort:"},{"location":"Sesion-2/Servicios/#load-balancer","text":"Expone el servicio de forma externa utilizando un balanceador (cloud, si se puede) y genera automaticamente un NodePort y un ClusterIP. $ cat loadBalancer-service.yaml apiVersion: extensions/v1beta1 kind: Ingress metadata: name: my-ingress spec: backend: serviceName: other servicePort: 8080 rules: - host: foo.mydomain.com http: paths: - backend: serviceName: foo servicePort: 8080 - host: mydomain.com http: paths: - path: /bar/* backend: serviceName: bar servicePort: 8080","title":"Load Balancer:"},{"location":"Sesion-2/Servicios/#externalname","text":"Mapea el servicio al exterior con un nombre definido. $ cat externalName-service.yaml apiVersion: extensions/v1beta1 kind: Service apiVersion: v1 metadata: name: my-service spec: type: ExternalName externalName: my.service.example.com","title":"ExternalName:"},{"location":"Sesion-2/Servicios/#ingress","text":"No es un servicio como tal, actua como un 'enrutador de servicios' $ cat ingress.yaml apiVersion: extensions/v1beta1 kind: Ingress metadata: name: my-ingress spec: backend: serviceName: other servicePort: 8080 rules: - host: foo.mydomain.com http: paths: - backend: serviceName: foo servicePort: 8080 - host: mydomain.com http: paths: - path: /bar/* backend: serviceName: bar servicePort: 8080","title":"Ingress:"}]}